{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handwritten Number Recognition Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_image, train_target_column), (test_image, test_target_column) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 圖片轉四維 (60000為圖片，大小為28X28，1表示單色)\n",
    "train_image_four_dimension = train_image.reshape(60000,28,28,1).astype('float32')\n",
    "test_image_four_dimension = test_image.reshape(10000,28,28,1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化，以利提升計算效率\n",
    "train_image_normalized = train_image_four_dimension / 255\n",
    "test_image_normalized = test_image_four_dimension / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將目標欄位轉為one hot encoder\n",
    "train_one_hot = np_utils.to_categorical(train_target_column)\n",
    "test_one_hot = np_utils.to_categorical(test_target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立CNN模型\n",
    "CNN = Sequential()\n",
    "CNN.add(Conv2D(filters = 16, kernel_size = (5, 5), padding='same', activation = 'relu', input_shape = (28, 28, 1)))\n",
    "CNN.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "CNN.add(Conv2D(filters = 36, kernel_size = (5, 5), padding='same', activation = 'relu'))\n",
    "CNN.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "CNN.add(Dropout(0.25))\n",
    "\n",
    "CNN.add(Flatten())\n",
    "\n",
    "CNN.add(Dense(units = 128, activation = 'relu'))\n",
    "\n",
    "CNN.add(Dropout(0.5))\n",
    "\n",
    "CNN.add(Dense(units = 10, activation = 'softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 36)        14436     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 36)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 7, 7, 36)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1764)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               225920    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 242,062\n",
      "Trainable params: 242,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      " - 63s - loss: 0.4751 - acc: 0.8509 - val_loss: 0.0981 - val_acc: 0.9700\n",
      "Epoch 2/15\n",
      " - 66s - loss: 0.1351 - acc: 0.9605 - val_loss: 0.0661 - val_acc: 0.9803\n",
      "Epoch 3/15\n",
      " - 70s - loss: 0.1034 - acc: 0.9686 - val_loss: 0.0584 - val_acc: 0.9820\n",
      "Epoch 4/15\n",
      " - 65s - loss: 0.0842 - acc: 0.9753 - val_loss: 0.0520 - val_acc: 0.9831\n",
      "Epoch 5/15\n",
      " - 56s - loss: 0.0693 - acc: 0.9791 - val_loss: 0.0481 - val_acc: 0.9853\n",
      "Epoch 6/15\n",
      " - 53s - loss: 0.0640 - acc: 0.9805 - val_loss: 0.0404 - val_acc: 0.9883\n",
      "Epoch 7/15\n",
      " - 52s - loss: 0.0554 - acc: 0.9835 - val_loss: 0.0375 - val_acc: 0.9895\n",
      "Epoch 8/15\n",
      " - 52s - loss: 0.0515 - acc: 0.9851 - val_loss: 0.0355 - val_acc: 0.9898\n",
      "Epoch 9/15\n",
      " - 48s - loss: 0.0454 - acc: 0.9861 - val_loss: 0.0370 - val_acc: 0.9898\n",
      "Epoch 10/15\n",
      " - 58s - loss: 0.0400 - acc: 0.9879 - val_loss: 0.0342 - val_acc: 0.9910\n",
      "Epoch 11/15\n",
      " - 57s - loss: 0.0391 - acc: 0.9879 - val_loss: 0.0336 - val_acc: 0.9900\n",
      "Epoch 12/15\n",
      " - 64s - loss: 0.0364 - acc: 0.9885 - val_loss: 0.0314 - val_acc: 0.9908\n",
      "Epoch 13/15\n",
      " - 66s - loss: 0.0333 - acc: 0.9897 - val_loss: 0.0348 - val_acc: 0.9913\n",
      "Epoch 14/15\n",
      " - 57s - loss: 0.0323 - acc: 0.9900 - val_loss: 0.0335 - val_acc: 0.9918\n",
      "Epoch 15/15\n",
      " - 63s - loss: 0.0299 - acc: 0.9905 - val_loss: 0.0306 - val_acc: 0.9918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1de20ca8d30>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN.fit(train_image_normalized, train_one_hot, validation_split=0.2, epochs=15, batch_size=300, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 431us/step\n",
      "預測精準度: 99.26 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = CNN.evaluate(test_image_normalized, test_one_hot)\n",
    "print('預測精準度:', accuracy[1]*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 424us/step\n"
     ]
    }
   ],
   "source": [
    "prediction = CNN.predict_classes(test_image_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 974,    0,    0,    0,    0,    0,    3,    0,    2,    1],\n",
       "       [   1, 1132,    1,    0,    0,    0,    1,    0,    0,    0],\n",
       "       [   1,    0, 1027,    0,    0,    0,    0,    3,    1,    0],\n",
       "       [   0,    0,    0, 1007,    0,    1,    0,    0,    2,    0],\n",
       "       [   0,    0,    0,    0,  974,    0,    0,    0,    2,    6],\n",
       "       [   1,    0,    0,    5,    0,  884,    1,    0,    0,    1],\n",
       "       [   4,    2,    0,    0,    1,    1,  949,    0,    1,    0],\n",
       "       [   0,    2,    4,    1,    0,    0,    0, 1016,    1,    4],\n",
       "       [   2,    0,    2,    1,    0,    1,    0,    1,  964,    3],\n",
       "       [   0,    1,    1,    0,    4,    3,    0,    1,    0,  999]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用混淆矩陣查看預測正確與錯誤的數字\n",
    "cm = confusion_matrix(test_target_column, prediction)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual value</th>\n",
       "      <th>predicted value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6625</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual value  predicted value\n",
       "582              8                2\n",
       "6625             8                2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 隨意抽取預測錯誤的圖片查看，由上可知，實際值為8、預測為2的數量有2個\n",
    "df = pd.DataFrame({'actual value': test_target_column, 'predicted value': prediction})\n",
    "df[(df['actual value']==8) & (df['predicted value']==2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual value</th>\n",
       "      <th>predicted value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4860</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9792</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual value  predicted value\n",
       "115              4                9\n",
       "740              4                9\n",
       "2130             4                9\n",
       "4860             4                9\n",
       "8527             4                9\n",
       "9792             4                9"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 隨意抽取預測錯誤的圖片查看，由上可知，實際值為4、預測為9的數量有個\n",
    "df = pd.DataFrame({'actual value': test_target_column, 'predicted value': prediction})\n",
    "df[(df['actual value']==4) & (df['predicted value']==9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪製圖形\n",
    "def plot_images(images, labels, prediction, idx, num = 1):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(12, 14)\n",
    "    \n",
    "    if num>25:\n",
    "        num=25 \n",
    "    \n",
    "    for i in range(0, num):\n",
    "        ax=plt.subplot(5,5, 1+i)\n",
    "        ax.imshow(images[idx], cmap='binary')\n",
    "        title= \"label = \" + str(labels[idx])\n",
    "\n",
    "        if len(prediction) > 0:\n",
    "            title+=\", predict = \" + str(prediction[idx])\n",
    "        \n",
    "        ax.set_title(title, fontsize = 10) \n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])        \n",
    "        idx+=1 \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1de22305940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 顯示預測錯誤的數字，實際是2，預測為0，由圖片可得知，字跡較潦草，確實辨別不易\n",
    "plot_images(test_image, test_target_column, prediction, idx=582)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1de243a8400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 預測錯誤的數字，實際是5，預測為3，由圖片可得知，字跡較潦草，確實辨別不易\n",
    "plot_images(test_image, test_target_column, prediction, idx=740)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 結論：\n",
    "    先前用MLP進行手寫辨識，預測精準度：97.69%；本次透過CNN進行預測，精準度再提升至99.26%。\n",
    "    隨意抽取幾個辨識錯誤的數字如上圖，確實連人類也難以判斷。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
